{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Workflow\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning\n",
    "<u>Model Selection:</u>  \n",
    "We will use 2 different classifiers for comparison.  We will use a [Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and [XGBoost Classifier](https://xgboost.readthedocs.io/en/stable/).  We will use these models to classify messages to the appropriate agency and test for accuracy.  \n",
    "\n",
    "<u>Evaluation Metric:</u><br><br>\n",
    "$Precision = \\frac{TP}{TP + FP}$<br><br>\n",
    "We will use Precision.  Precision is the ratio of correctly predicted positive observations to the total predicted positives.  Precision is a good measure to determine, when the costs of False Positive is high.  In this case, a False positive will result in leaving someone stranded, who needs help.\n",
    "    \n",
    "\n",
    "### Pipeline Workflow\n",
    "\n",
    "\n",
    "### Model Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import re # for regular expressions\n",
    "import numpy as np # numeric python, vector operations\n",
    "import pandas as pd # data manipulation\n",
    "from nltk.corpus import stopwords # natural language tool kit: stopwords\n",
    "from nltk.tokenize import word_tokenize # natural language tool kit: word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer # natural language tool kit: lemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer # for text processing\n",
    "from sklearn.model_selection import train_test_split # for splitting data into training and testing\n",
    "from sklearn.multioutput import MultiOutputClassifier   # for multi-output classification\n",
    "from sklearn.ensemble import RandomForestClassifier # for random forest classifier\n",
    "from sklearn.pipeline import Pipeline   # for creating a pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score # for model evaluation\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Load the dataset\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///../data/disaster_response.db')\n",
    "df = pd.read_sql_table('features', engine) \n",
    "X = df['message']\n",
    "y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a Customer Text Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom text transformer\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    This function takes a text and returns a list of cleaned and tokenized words.\n",
    "    Designed to be used in a pipeline, with the CountVectorizer and TfidfTransformer objects\n",
    "\n",
    "    Args:\n",
    "    text: str: a string of text to be tokenized\n",
    "\n",
    "    Returns:\n",
    "    lemmed: list: a list of cleaned and tokenized words\n",
    "    \"\"\"\n",
    "    # Normalize text\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # Tokenize text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    \n",
    "    # Lemmatization\n",
    "    words = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "\n",
    "    # Stemming (not used, does not improve performance)\n",
    "    # stemmed = [PorterStemmer().stem(w) for w in lemmed]\n",
    "    \n",
    "    return words\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Tokenization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attVuono sandy hook is just gonna float away hahaha\n",
      "['attvuono', 'sandy', 'hook', 'gon', 'na', 'float', 'away', 'hahaha'] \n",
      "\n",
      "Koyo Ecological Agrotech (Group) Ltd., together with its subsidiaries, is engaged in the research and development, manufacture, marketing and distribution of chemical products, chemical fertilizers and bulk blending fertilizers.\n",
      "['koyo', 'ecological', 'agrotech', 'group', 'ltd', 'together', 'subsidiary', 'engaged', 'research', 'development', 'manufacture', 'marketing', 'distribution', 'chemical', 'product', 'chemical', 'fertilizer', 'bulk', 'blending', 'fertilizer'] \n",
      "\n",
      "WFP and counterparts quickly set up telethons to replace lost commodities and assist families in restarting the projects.\n",
      "['wfp', 'counterpart', 'quickly', 'set', 'telethons', 'replace', 'lost', 'commodity', 'assist', 'family', 'restarting', 'project'] \n",
      "\n",
      "Typhoon Reming in 2006 was one of those super typhoons caused by climate change.\n",
      "['typhoon', 'reming', '2006', 'one', 'super', 'typhoon', 'caused', 'climate', 'change'] \n",
      "\n",
      "in what place is The National archive? to give the I date that he/it takes his/its function \n",
      "['place', 'national', 'archive', 'give', 'date', 'take', 'function'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test out function\n",
    "for message in X.sample(5):\n",
    "    tokens = tokenize(message)\n",
    "    print(message)\n",
    "    print(tokens, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline will have 3 steps\n",
    "# 1. CountVectorizer - Convert a collection of text documents to a matrix of token counts\n",
    "# 2. TfidfTransformer - Transform a count matrix to a normalized tf or tf-idf representation\n",
    "# 3. MultiOutputClassifier - This is a simple meta-estimator for fitting one classifier per target.\n",
    "def build_pipeline():\n",
    "    \"\"\"\n",
    "    This function builds a pipeline for text processing and multi-output classification\n",
    "\n",
    "    Returns:\n",
    "    pipeline: Pipeline: a pipeline object that processes text and classifies it\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline([ \n",
    "        ('vect', CountVectorizer(tokenizer=tokenize,\n",
    "                                min_df=5,\n",
    "                                max_df=0.75)), # here is where you use the custom text transformer\n",
    "        ('tfidf', TfidfTransformer()), # use the TfidfTransformer\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier(verbose=1))) # use the RandomForestClassifier  \n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "pipeline = build_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train pipeline with the Benchmark model (we will look to improve through more iterations)\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe the hyperparameters of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect', CountVectorizer(max_df=0.75, min_df=5,\n",
       "                   tokenizer=<function tokenize at 0x1638302c0>)),\n",
       "  ('tfidf', TfidfTransformer()),\n",
       "  ('clf', MultiOutputClassifier(estimator=RandomForestClassifier(verbose=1)))],\n",
       " 'verbose': False,\n",
       " 'vect': CountVectorizer(max_df=0.75, min_df=5,\n",
       "                 tokenizer=<function tokenize at 0x1638302c0>),\n",
       " 'tfidf': TfidfTransformer(),\n",
       " 'clf': MultiOutputClassifier(estimator=RandomForestClassifier(verbose=1)),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 0.75,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 5,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__estimator__bootstrap': True,\n",
       " 'clf__estimator__ccp_alpha': 0.0,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': 'sqrt',\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__max_samples': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__monotonic_cst': None,\n",
       " 'clf__estimator__n_estimators': 100,\n",
       " 'clf__estimator__n_jobs': None,\n",
       " 'clf__estimator__oob_score': False,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__verbose': 1,\n",
       " 'clf__estimator__warm_start': False,\n",
       " 'clf__estimator': RandomForestClassifier(verbose=1),\n",
       " 'clf__n_jobs': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show params for benchmark model\n",
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the hyperparameters listed above, we will focus on the following:\n",
    "\n",
    " ```'vect__max_df: 0.75'``` Maximum document frequency for each term up to 75% of the document<br><br>\n",
    " ```'vect__min_df: 5'``` Minimum document frequency for each term is 5<br><br>\n",
    " ```'clf__estimator__n_estimators: 100'``` Number of trees in the forest, each tree in the forest is built on a subsert of the training data and makes it's own predictions.  The final prediction is made by averaging the predictions of each individual tree.  Increasing the number of trees increases the diversity in data the model is trained on, improving accuracy.  But that comes with a cost in computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training observations: 20972\n",
      "total testing observations: 5244\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# show shape of the different datsets\n",
    "print(f'total training observations: {X_train.shape[0]}')\n",
    "print(f'total testing observations: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    7.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(max_df=0.75, min_df=5,\n",
       "                                 tokenizer=&lt;function tokenize at 0x1638302c0&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(verbose=1)))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(max_df=0.75, min_df=5,\n",
       "                                 tokenizer=&lt;function tokenize at 0x1638302c0&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(verbose=1)))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(max_df=0.75, min_df=5,\n",
       "                tokenizer=&lt;function tokenize at 0x1638302c0&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\">?<span>Documentation for TfidfTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfTransformer()</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;clf: MultiOutputClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.multioutput.MultiOutputClassifier.html\">?<span>Documentation for clf: MultiOutputClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MultiOutputClassifier(estimator=RandomForestClassifier(verbose=1))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(verbose=1)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(verbose=1)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(max_df=0.75, min_df=5,\n",
       "                                 tokenizer=<function tokenize at 0x1638302c0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(verbose=1)))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train classifier\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model - 1st iteration\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create reusable function to evaluate model performance for all 36 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X_test,y_test,estimator,iteration):\n",
    "    \"\"\"\n",
    "        Evaluate the model by calculating the precision, recall, and f1-score for each label\n",
    "    \n",
    "        Args:\n",
    "        X_test: the test features\n",
    "        y_test: the test labels\n",
    "        estimator: the trained model\n",
    "        iteration: the current model iteration\n",
    "    \n",
    "        Returns:\n",
    "        results: a dataframe containing the precision for the current model iteration\n",
    "    \"\"\"\n",
    "    # import report that captures appropriate metrics\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    # predict on test data\n",
    "    y_pred = estimator.predict(X_test)\n",
    "\n",
    "    # initialize an empty dataframe to store the results\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    # calculate and store the precision, recall, and f1-score for each label\n",
    "    for i, col in enumerate(y_test.columns):\n",
    "        report = classification_report(y_test[col], y_pred[:, i], output_dict=True)\n",
    "        df = pd.DataFrame(report).transpose()\n",
    "        df['label'] = col\n",
    "        results = pd.concat([results, df])\n",
    "\n",
    "    # reset the index of the results dataframe\n",
    "    results.reset_index(inplace=True)\n",
    "    results.rename(columns={'index': 'metric'}, inplace=True)\n",
    "\n",
    "    # rearrange the columns to put 'label' first\n",
    "    cols = ['label'] + [col for col in results.columns if col != 'label']\n",
    "    results = results[cols]\n",
    "\n",
    "    # round the results to 2 decimal places\n",
    "    results = results.round(2)\n",
    "\n",
    "    # convert the 'support' column to integers\n",
    "    results.support = results.support.astype(int)\n",
    "\n",
    "    # add the iteration number to column names, skipping label and metric columns\n",
    "    results.columns = [f'{col}_{iteration}' if col not in ['label', 'metric'] else col for col in results.columns]\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>metric</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>support_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>related</td>\n",
       "      <td>0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>related</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>related</td>\n",
       "      <td>2</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>related</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>related</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "      <td>5244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>direct_report</td>\n",
       "      <td>1</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>direct_report</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>direct_report</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "      <td>5244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>direct_report</td>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>5244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label        metric  precision_1  recall_1  f1-score_1  support_1\n",
       "0          related             0         0.69      0.46        0.55       1214\n",
       "1          related             1         0.85      0.93        0.89       3987\n",
       "2          related             2         0.39      0.40        0.39         43\n",
       "3          related      accuracy         0.82      0.82        0.82          0\n",
       "4          related     macro avg         0.64      0.60        0.61       5244\n",
       "..             ...           ...          ...       ...         ...        ...\n",
       "175  direct_report             0         0.86      0.97        0.91       4194\n",
       "176  direct_report             1         0.77      0.36        0.49       1050\n",
       "177  direct_report      accuracy         0.85      0.85        0.85          0\n",
       "178  direct_report     macro avg         0.81      0.66        0.70       5244\n",
       "179  direct_report  weighted avg         0.84      0.85        0.83       5244\n",
       "\n",
       "[180 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model, 1st iteration\n",
    "results1 = evaluate_models(X_test,y_test,pipeline,1)\n",
    "\n",
    "results1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters<br>\n",
    "<br>\n",
    "We will use GridSearchCV to search within the best params under the following hyperparameters:<br>\n",
    "```'clf__estimator__n_estimators': [150, 200]```<br>\n",
    "```'clf__estimator__min_samples_split': [2, 3]```<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.5s\n"
     ]
    }
   ],
   "source": [
    "# use grid search to find better parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# pipeline\n",
    "pipeline = build_pipeline()\n",
    " \n",
    "# adding parameters will increase time exponentially\n",
    "parameters = {\n",
    "    'clf__estimator__n_estimators':[150, 200],\n",
    "    'clf__estimator__min_samples_split':[3, 4]\n",
    "}\n",
    "\n",
    "# instantiate grid search object with appropriate parameters\n",
    "cv = GridSearchCV(pipeline, \n",
    "                  param_grid=parameters, \n",
    "                  verbose=1, \n",
    "                  cv=5, \n",
    "                  n_jobs=1, \n",
    "                  return_train_score=True,\n",
    "                  scoring='f1')\n",
    "\n",
    "# train the model\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the average training and test scores from the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is an issue with the GridSearch object\n",
    "There may be an issue using the multioutputclassifier in gridsearch.  That's all I can come up with at this point.  In the past, with other models, I haven't had this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model - 2nd iteration\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model - 2nd iteration    \n",
    "results2 = evaluate_models(X_test,y_test,cv,2)\n",
    "\n",
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the best parameters\n",
    "print('best parameters:', cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Train the model on the best parameters and evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline\n",
    "pipeline = build_pipeline()\n",
    "\n",
    "# set pareters to best parameters from grid search\n",
    "pipeline.set_params(**cv.best_params_)\n",
    "\n",
    "# fit the model\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model - 3rd iteration\n",
    "results3 = evaluate_models(X_test,y_test,pipeline,3)\n",
    "\n",
    "results3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.  Improve Model Performance: Train another classifer\n",
    "We will attempt to train the same pipline with an XGboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the XGBoost classifier for multiclass objective function\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# create a pipeline for the XGBoost classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize,\n",
    "                             min_df=5, # min doc frequency 5 occurences\n",
    "                             max_df=0.75)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.01,    \n",
    "        verbosity=1)))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "results4 = evaluate_models(X_test, y_test, pipeline,4)\n",
    "\n",
    "results4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Compare training results with the benchmark model\n",
    "The second model is clearly not catching the true positive classes<br>\n",
    "We will attempt to train on a different classifer to see if we can improve accuracy<br>\n",
    "<br>\n",
    "Now we will look closer at the different model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all dataframes\n",
    "\n",
    "# create a list for functools.reduce\n",
    "dfs = [results1, results2, results3, results4]\n",
    "\n",
    "# import the library\n",
    "from functools import reduce\n",
    "\n",
    "# merge the dataframes\n",
    "results = reduce(lambda left,right: pd.merge(left,right,on=['label','metric']), dfs)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('../models/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create reusable function to extract metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to summarize results \n",
    "def results_df(df,metric):\n",
    "    \"\"\"\n",
    "    This takes a dataframe and a metric, then filters the dataframe to only include the metric of interest.\n",
    "\n",
    "    Args:\n",
    "    df: DataFrame: a dataframe containing the results of the model evaluation\n",
    "    metric: str: the metric of interest\n",
    "\n",
    "    Returns:\n",
    "    df: DataFrame: a dataframe containing the results of the model evaluation, filtered by the metric of interest\n",
    "    \n",
    "    \"\"\"\n",
    "    # take the first 2 columns, then filter by metric\n",
    "    df = df[['label','metric']+[col for col in df.columns if metric in col]]\n",
    "\n",
    "    # relabel the columns, based on model iteration\n",
    "    df.columns = ['label', 'metric', 'benchmark', 'grid_search', 'best_params', 'xgboost']\n",
    "\n",
    "    # create a new column that contains the best model\n",
    "    df['best_model'] = df[['benchmark', 'grid_search','best_params', 'xgboost']].idxmax(axis=1)\n",
    "\n",
    "    df = df.loc[df['metric'] == 'macro avg']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = results_df(results,'precision')\n",
    "\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "precision_plot = precision.best_model.value_counts(normalize=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "sns.barplot(x=precision_plot.index, y=precision_plot.values, ax=ax)\n",
    "ax.set_title('Best Model by Precision')\n",
    "ax.set_ylabel('Percentage')\n",
    "plt.axhline(0.388889, color='gray', linestyle='--', label='Benchmark')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df for f1 scores\n",
    "f1 = results_df(results,'f1')\n",
    "\n",
    "# plot results\n",
    "f1.iloc[:,2:6].mean().plot(kind='bar', figsize=(10,5), title='Average F1 Score by Model Iteration')\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,.75)\n",
    "plt.axhline(f1.iloc[:,2:6].mean().mean(), color='gray', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the X_train data through the pipeline\n",
    "X_train_processed = pipeline.named_steps['vect'].transform(X_train)\n",
    "X_train_processed = pipeline.named_steps['tfidf'].transform(X_train_processed)\n",
    "\n",
    "# extract the feature names\n",
    "feature_names = pipeline.named_steps['vect'].get_feature_names_out()\n",
    "\n",
    "# extract the feature importances\n",
    "feature_importances = pipeline.named_steps['clf'].estimators_[0].feature_importances_\n",
    "\n",
    "# create a dataframe with the feature names and importances\n",
    "df = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n",
    "\n",
    "# save df to csv\n",
    "df.to_csv('../data/feature_importances.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract The Training and Test Data to see Distribution of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df with X_train_processed\n",
    "X_train_df = pd.DataFrame(X_train_processed.toarray(), columns=feature_names)\n",
    "\n",
    "# merge with y_train\n",
    "X_train_df = pd.concat([X_train_df, y_train.reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_train_df.shape\n",
    "\n",
    "# save X_train_df to csv\n",
    "X_train_df.to_csv('../data/X_train_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract test features\n",
    "X_test_processed = pipeline.named_steps['vect'].transform(X_test)\n",
    "X_test_processed = pipeline.named_steps['tfidf'].transform(X_test_processed)\n",
    "\n",
    "# create df with X_test_processed\n",
    "X_test_df = pd.DataFrame(X_test_processed.toarray(), columns=feature_names)\n",
    "\n",
    "# merge with y_test\n",
    "X_test_df = pd.concat([X_test_df, y_test.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# save to csv\n",
    "X_test_df.to_csv('../data/X_test_df.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Model Training Iterations\n",
    "1.  Benchmark model: RandomForestClassifier - showed 95% accuracy\n",
    "2.  Grid Search: We tried 4 different sets of hyperparameters with cross validation.  However, the model seriously underfit and could not detect most of the postive classes.\n",
    "3.  XGBoost - We tried XGBoost with GridSearch and it showed 95% accuracy.  We saved this model as the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export your model as a pickel file\n",
    "import joblib\n",
    "with open('xgb_classifier.pkl', 'wb') as file:\n",
    "    joblib.dump(pipeline, file, compress=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train_classifier.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
